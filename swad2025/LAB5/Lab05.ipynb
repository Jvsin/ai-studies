{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedecc37",
   "metadata": {},
   "source": [
    "## Laboratorium 5 - algorytm Najbliższej Średniej (NM)\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest implementacja klasyfikatora najbliższej średniej NM (*Nearest Mean*).\n",
    "\n",
    "\n",
    "### Zadanie 1\n",
    "* Wczytaj dane.\n",
    "* Wszystkie poniższe zadania wykonaj dla wszystkich dostępnych klas i wszystkich cech.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c95f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 14) (2244,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    train, test = data['train'], data['test']\n",
    "\n",
    "y_train = train[:,0]\n",
    "X_train = train[:,2:]\n",
    "y_test = test[:,0]\n",
    "X_test = test[:,2:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60209851",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "Zaimplementuj klasyfikator najbliższej średniej (NM) z zastosowaniem odległości Euklidesa i wykonaj klasyfikację. Wyświetl wynik klasyfikacji (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5178ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasa 0: [8.04829893e-01 1.70366987e+00 4.25848188e-01 9.73543273e-01\n",
      " 9.93903017e-01 7.73864549e-01 5.79951347e-03 3.87482009e-03\n",
      " 2.03802164e-02 7.15419902e-02 6.15755177e-03 1.86811787e-03\n",
      " 1.02716254e-04 5.83331644e-01]\n",
      "Klasa 10: [4.28650065e-01 1.07883572e+00 6.65407177e-01 5.32168458e-01\n",
      " 6.33272125e-01 1.51801982e-01 1.26683428e-01 2.93407580e+00\n",
      " 2.67988196e-02 8.99281742e-02 8.17501461e-03 2.62608981e-03\n",
      " 1.35328803e-04 8.09846330e-01]\n",
      "Klasa 20: [7.80214459e-01 1.56916889e+00 3.88187822e-01 9.88153389e-01\n",
      " 1.01569482e+00 8.08649353e-01 5.88184477e-03 1.45377038e-02\n",
      " 3.28249659e-02 9.25700882e-02 8.85827555e-03 2.48925335e-03\n",
      " 2.88838902e-04 1.11486375e+00]\n",
      "\n",
      "Accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def nearestMean_fit(X, y):\n",
    "    centroids = {}\n",
    "    y_classes = np.unique(y)\n",
    "    for y_class in y_classes:\n",
    "        centroids[y_class] = X[y == y_class].mean(axis=0)\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Klasa {i}: {centroids[centroid]}\")\n",
    "    return centroids, y_classes\n",
    "\n",
    "def nearestMean_predict(X, centroids, y):\n",
    "    y_classes = np.unique(y)\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        distances = {}\n",
    "        for y_class in y_classes: \n",
    "            distances[y_class] = np.linalg.norm(x - centroids[y_class])\n",
    "        # print(distances)\n",
    "        pred = min(distances, key=distances.get)\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)\n",
    "\n",
    "centroids, y_classes = nearestMean_fit(X_train, y_train)\n",
    "predictions = nearestMean_predict(X_test, centroids, y_classes)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cecb0d",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "Zaimplementuj funkcję, która zwraca macierz kowariancji (*uwaga: biblioteka `numpy` posiada gotową implementację `cov` z którą powinieneś porównać swój wynik*).\n",
    "\n",
    "\\begin{equation*}\n",
    "C = \\frac{1}{n - 1} (X - \\bar X)(X - \\bar X)^T\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie:\n",
    "* $X$ to macierz danych,\n",
    "* $\\bar X$ to wektor średnich wartości cech. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84154865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n"
     ]
    }
   ],
   "source": [
    "def cov_matrix(X):\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_centered = X - X_mean\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    C = (1 / (n - 1)) * np.dot(X_centered.T, X_centered)\n",
    "    \n",
    "    return C\n",
    "\n",
    "own_cov = cov_matrix(X_train)\n",
    "np_cov = np.cov(X_train, rowvar=False)\n",
    "print(own_cov[0] == np_cov[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e948f9",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "Zaimplementuj klasyfikator najbliższej średniej (NM) z zastosowaniem odległości Mahalanobisa i wykonaj klasyfikację. Wyświetl wynik klasyfikacji (accuracy).\n",
    "\n",
    "\\begin{equation*}\n",
    "D_j = \\sqrt{ (x - \\mu_j)^T S_j^{-1}(x - \\mu_j) },\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie:\n",
    "* $D_j$ to odległość klasyfikowanej próbki od klasy $j$, \n",
    "* $\\mu_j$ to wektor średnich wartości cech dla klasy $j$, \n",
    "* $S_j^{-1}$ to macierz odwrotna do macierzy kowariancji klasy $j$, \n",
    "* a $x$ to klasyfikowana próbka.\n",
    "\n",
    "> Podpowiedź: Do obliczenia macierzy odwrotnej możesz użyć funkcji `linalg.inv` z biblioteki `numpy`.\n",
    "\n",
    "> UWAGA: W niniejszym zadaniu możesz zastosować dowolną strukturę kodu (nie musisz trzymać się struktury z poprzedniego zadania), jednak algorytm NM należy zaimplementować samodzielnie – bez użycia gotowych rozwiązań (np. z biblioteki `scikit-learn`).\n",
    "\n",
    "<span style=\"text-decoration:underline\">Referencje</span>\n",
    "\n",
    "1. Mahalanobis, P C, _On test and measures of group divergence : theoretical formulae_, Journal and Proceedings of Asiatic Society of Bengal (New Series) Vol. 26, pp. 541-588. 1930. (URL: http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/1639/029.pdf)\n",
    "2. McLachlan, Goeffrey J. _Mahalanobis distance_, Resonance, pp. 20-26. 1999. (URL: https://www.ias.ac.in/article/fulltext/reso/004/06/0020-0026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5df2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczność: 56.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def mahalanobis_distance(x, centroid, inv_cov):\n",
    "    diff = x - centroid\n",
    "    distance = np.sqrt(diff.T @ inv_cov @ diff)\n",
    "    return distance\n",
    "\n",
    "def nearestMean_fit(X, y):\n",
    "    centroids = {}\n",
    "    inv_covs = {} \n",
    "    y_classes = np.unique(y)\n",
    "\n",
    "    for y_class in y_classes:\n",
    "        X_class = X[y == y_class]\n",
    "        centroids[y_class] = X_class.mean(axis=0)\n",
    "        \n",
    "        cov = np.cov(X_class, rowvar=False)\n",
    "        inv_covs[y_class] = np.linalg.inv(cov)\n",
    "    return centroids, inv_covs, y_classes\n",
    "\n",
    "def nearestMean_predict(X, centroids, inv_covs, y):\n",
    "    y_classes = np.unique(y)\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        distances = {}\n",
    "        for y_class in y_classes:\n",
    "            distances[y_class] = mahalanobis_distance(x, centroids[y_class], inv_covs[y_class])\n",
    "        pred = min(distances, key=distances.get)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "centroids, inv_covs, y_classes = nearestMean_fit(X_train, y_train)\n",
    "\n",
    "predictions = nearestMean_predict(X_test, centroids, inv_covs, y_train)\n",
    "print(f\"Skuteczność: {accuracy_score(y_test, predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b6b44-a7da-4183-9c50-59a0d182e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "email": "robert.susik@p.lodz.pl",
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
